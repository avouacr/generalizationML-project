# generalizationML-project

**Sujet :** En apprentissage supervisé classique, les méthodes de réduction de variance
(SAG, SVRG) combinent des updates de faible complexité (similaire à SGD) à
un taux de convergence rapide. Cependant, ces méthodes sont peu utilisées en
pratique en Deep Learning.

Le but de ce projet est de comparer le score de généralisation de différentes
méthodes d'optimisation dans le cadre d'une architecture simple de Deep
Learning pour une tache de vision.

**Données :** CIFAR-10.

**Algorithmes comparés :** SGD, Adam, GD, SVGR, SGD with averaging.
